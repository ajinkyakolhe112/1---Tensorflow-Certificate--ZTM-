{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Certification\n",
    "   2. Tensorflow 2.15 & Keras 3.0 conflicts of installation. Pytorch doesn't have that problem. *couldn't get vscode to work, used colab*\n",
    "   3. Lots of inconsistent & incoherent features. Pytorch is coherent in features. \n",
    "   4. Side Effect of Pytorch/TF: Lots of boilerplate / glue code. `Glue Code or BoilerPlate Code: Lots of lines but only a minor functionality.` Maintain standard workflow cookbook.\n",
    "   5. **Annoying to make some things work**\n",
    "   6. Personal Opinion. \n",
    "      1. Use Pytorch for training loop, if you want to use tensorflow, use it just for model architecture.\n",
    "      2. Future: Using Jax or Tensorflow for speedup. Then use keras 3.0, same api, and multiple backends. No need to learn different libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Preprocess data (get all of the pixel values between 1 and 0, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup the train and test directories\n",
    "train_dir = \"pizza_steak/train/\"\n",
    "test_dir = \"pizza_steak/test/\"\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(train_dir,\n",
    "                                               batch_size=32, # number of images to process at a time \n",
    "                                               target_size=(224, 224), # convert all images to be 224 x 224\n",
    "                                               class_mode=\"binary\", # type of problem we're working on\n",
    "                                               seed=42)\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(test_dir,\n",
    "                                               batch_size=32,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"binary\",\n",
    "                                               seed=42)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/Users/ajinkya/.cache/huggingface/datasets/ajinkyakolhe112___parquet/ajinkyakolhe112--pizza_vs_steak_classification-41ef506b044d97dc/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abede7b47b948dab918f0e65ee6d575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'train': (1500, 2), 'test': (500, 2)},\n",
       " {'image': Image(decode=True, id=None),\n",
       "  'label': ClassLabel(names=['pizza', 'steak'], id=None)})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets as huggingface_datasets\n",
    "\n",
    "dataset_splits = huggingface_datasets.load_dataset(\"ajinkyakolhe112/pizza_vs_steak_classification\")\n",
    "dataset_training, dataset_validation = dataset_splits['train'], dataset_splits['test']\n",
    "\n",
    "huggingface_datasets.get_dataset_split_names(\"ajinkyakolhe112/pizza_vs_steak_classification\")\n",
    "dataset_splits.shape, dataset_splits['train'].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_func(examples_batch):\n",
    "    examples_batch['new'] = []\n",
    "    for image in examples_batch:\n",
    "        pass\n",
    "    return examples_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Convert to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinkya/anaconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:388: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_training_tf   = dataset_training.with_format(\"tf\")\n",
    "dataset_validation_tf = dataset_validation.with_format(\"tf\")\n",
    "\n",
    "training_dataset_tf   = dataset_training.to_tf_dataset(columns=[\"image\"], label_cols=[\"label\"], batch_size=4, shuffle=True)\n",
    "validation_dataset_tf = dataset_validation.to_tf_dataset(columns=[\"image\"], label_cols=[\"label\"], batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <tf.Tensor: shape=(384, 512, 3), dtype=uint8, numpy=\n",
       " array([[[ 38,  41,  22],\n",
       "         [ 34,  37,  18],\n",
       "         [ 41,  44,  25],\n",
       "         ...,\n",
       "         [ 68,  72,  57],\n",
       "         [ 63,  67,  52],\n",
       "         [ 58,  62,  47]],\n",
       " \n",
       "        [[ 37,  40,  21],\n",
       "         [ 32,  35,  16],\n",
       "         [ 36,  39,  20],\n",
       "         ...,\n",
       "         [ 65,  69,  54],\n",
       "         [ 62,  66,  51],\n",
       "         [ 59,  63,  48]],\n",
       " \n",
       "        [[ 41,  44,  25],\n",
       "         [ 37,  40,  21],\n",
       "         [ 37,  40,  21],\n",
       "         ...,\n",
       "         [ 52,  56,  42],\n",
       "         [ 49,  53,  39],\n",
       "         [ 48,  52,  38]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[109, 114,  84],\n",
       "         [110, 115,  85],\n",
       "         [110, 115,  85],\n",
       "         ...,\n",
       "         [109, 123,  90],\n",
       "         [106, 120,  87],\n",
       "         [104, 118,  85]],\n",
       " \n",
       "        [[110, 115,  85],\n",
       "         [111, 116,  86],\n",
       "         [111, 116,  86],\n",
       "         ...,\n",
       "         [106, 120,  87],\n",
       "         [104, 118,  85],\n",
       "         [101, 115,  82]],\n",
       " \n",
       "        [[108, 113,  83],\n",
       "         [109, 114,  84],\n",
       "         [110, 115,  85],\n",
       "         ...,\n",
       "         [105, 119,  86],\n",
       "         [102, 116,  83],\n",
       "         [ 99, 113,  80]]], dtype=uint8)>,\n",
       " 'label': <tf.Tensor: shape=(), dtype=int64, numpy=0>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_training_tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# dataset_training, dataset_validation = dataset_splits['train'], dataset_splits['test']\n",
    "# dataset_training, dataset_validation = dataset_training.with_format(\"torch\"), dataset_validation.with_format(\"torch\")\n",
    "\n",
    "# training_dataloader   = torch.utils.data.DataLoader(dataset_training, batch_size=32, shuffle= True)\n",
    "# validation_dataloader = torch.utils.data.DataLoader(dataset_training, batch_size=32, shuffle= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Rest \n",
    "   5. Don't remember library. (Can't be remembered anyways. Get used to documentation)\n",
    "   6. Do remember deep learning concepts. (These need to be mastered.)\n",
    "   7. Essential Checklist Concepts. (MUST BE MASTERED THOROUGHLY. IF WANT TO BE A MASTER.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [ ] downloading **datasets** & starting training. -> ans: huggingface datasets. standard way of uploading dataset. dataset to dataloader in pytorch & in tensorflow via huggingface\n",
    "- [ ] **model**. sequential is easy but can't debug properly -> ans: functional api or extending model. (2 ways)\n",
    "- [ ] **training** loop from that dataset. both in pytorch & tensorflow -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "# Sequential doesn't allow debugging & internal layer output. This format does.\n",
    "class BaselineModel (keras.Model):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super().__init__()\n",
    "        self.layers_list = [\n",
    "            keras.layers.Conv2D        (filters= 10, kernel_size=(3,3), activation=\"relu\", input_shape=(224, 224, 3)), \n",
    "            keras.layers.Conv2D        (filters= 10, kernel_size=(3,3), activation=\"relu\"),\n",
    "            keras.layers.MaxPool2D     (pool_size=(2,2), padding=\"valid\"),\n",
    "\n",
    "            keras.layers.Conv2D        (filters= 10, kernel_size=(3,3), activation=\"relu\"),\n",
    "            keras.layers.Conv2D        (filters= 10, kernel_size=(3,3), activation=\"relu\"), \n",
    "            keras.layers.MaxPool2D     (pool_size=(2,2)),\n",
    "            \n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense         (units= 1, activation=\"sigmoid\")\n",
    "        ]\n",
    "\n",
    "    def call(self, single_batch):\n",
    "        current_input = single_batch\n",
    "        for current_layer in self.layers_list:\n",
    "            layer_output = current_layer(current_input)\n",
    "            current_input = layer_output\n",
    "\n",
    "        return layer_output                                 # type:ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajinkya/anaconda3/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "model = BaselineModel()\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 14:40:35.128109: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1500]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-09 14:40:35.128312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1500]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-01-09 14:40:35.168619: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001b[1mValue passed to parameter 'input' has DataType int64 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(None, None, None, 3), dtype=int64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history_1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(training_dataset_tf, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mvalidation_dataset_tf)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m, in \u001b[0;36mBaselineModel.call\u001b[0;34m(self, single_batch)\u001b[0m\n\u001b[1;32m     21\u001b[0m current_input \u001b[38;5;241m=\u001b[39m single_batch\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m current_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers_list:\n\u001b[0;32m---> 23\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m current_layer(current_input)\n\u001b[1;32m     24\u001b[0m     current_input \u001b[38;5;241m=\u001b[39m layer_output\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling Conv2D.call().\n\n\u001b[1mValue passed to parameter 'input' has DataType int64 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001b[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(None, None, None, 3), dtype=int64)"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history_1 = model.fit(training_dataset_tf, epochs=5, validation_data=validation_dataset_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
